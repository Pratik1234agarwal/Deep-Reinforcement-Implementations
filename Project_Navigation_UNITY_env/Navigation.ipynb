{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigation\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing some necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Banana.app\"`\n",
    "- **Windows** (x86): `\"path/to/Banana_Windows_x86/Banana.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Banana_Windows_x86_64/Banana.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Banana_Linux/Banana.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Banana_Linux/Banana.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Banana_Linux_NoVis/Banana.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Banana_Linux_NoVis/Banana.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Banana.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Banana.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: BananaBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 37\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=\"Banana_Windows_x86_64/Banana.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "The simulation contains a single agent that navigates a large environment.  At each time step, it has four actions at its disposal:\n",
    "- `0` - walk forward \n",
    "- `1` - walk backward\n",
    "- `2` - turn left\n",
    "- `3` - turn right\n",
    "\n",
    "The state space has `37` dimensions and contains the agent's velocity, along with ray-based perception of objects around agent's forward direction.  A reward of `+1` is provided for collecting a yellow banana, and a reward of `-1` is provided for collecting a blue banana. \n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 1\n",
      "Number of actions: 4\n",
      "States look like: [1.         0.         0.         0.         0.84408134 0.\n",
      " 0.         1.         0.         0.0748472  0.         1.\n",
      " 0.         0.         0.25755    1.         0.         0.\n",
      " 0.         0.74177343 0.         1.         0.         0.\n",
      " 0.25854847 0.         0.         1.         0.         0.09355672\n",
      " 0.         1.         0.         0.         0.31969345 0.\n",
      " 0.        ]\n",
      "States have length: 37\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents in the environment\n",
    "print('Number of agents:', len(env_info.agents))\n",
    "\n",
    "# number of actions\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Number of actions:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "state = env_info.vector_observations[0]\n",
    "print('States look like:', state)\n",
    "state_size = len(state)\n",
    "print('States have length:', state_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "The next code cell demonstrates how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Once this cell is executed, you will watch the agent's performance, if it selects an action (uniformly) at random with each time step.  A window should pop up that allows you to observe the agent, as it moves through the environment.  \n",
    "\n",
    "Later we are going to implement the **DQN** agent to get better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: -1.0\n"
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name] # reset the environment\n",
    "state = env_info.vector_observations[0]            # get the current state\n",
    "score = 0                                          # initialize the score\n",
    "while True:\n",
    "    action = np.random.randint(action_size)        # select an action\n",
    "    env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "    next_state = env_info.vector_observations[0]   # get the next state\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    score += reward                                # update the score\n",
    "    state = next_state                             # roll over the state to next time step\n",
    "    if done:                                       # exit loop if episode finished\n",
    "        break\n",
    "    \n",
    "print(\"Score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing usual packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim \n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque,namedtuple\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Defining the Deep Neural Network \n",
    "The following cell defines the neural network architecture . \n",
    "It uses 3 fully connected layers \n",
    "the hidden layers have size **64** and **32** , and has **RELU** activation applied to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self,input_size,output_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_size,64)\n",
    "        self.fc2 = nn.Linear(64,32)\n",
    "        self.fc3 = nn.Linear(32,4)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Building the agent using Deep Q Network\n",
    "The following cell implements the agent using the [DQN](https://www.nature.com/articles/nature14236) technique . \n",
    "The agent recieves the enviorement information and learn from it .\n",
    "\n",
    "### Some Hyperparamerters list :-\n",
    "1. **epsilon**  = 1 *decays gradually*\n",
    "2. **gamma** = 0.99\n",
    "3. **batch size** = 32 (for experience replay)\n",
    "4. **Optimizer** = ADAM\n",
    "5. **Learning rate**  = 0.001\n",
    "6. **buffer size** = $10^5$\n",
    "7. **Tau** = $10^-3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self,input_size,output_size):\n",
    "        \n",
    "        # Some hyperparameters\n",
    "        self.epsilon=1\n",
    "        self.eps_decay = 0.9\n",
    "        self.gamma = 0.99\n",
    "        self.input_size = input_size\n",
    "        self.action_size = output_size\n",
    "        self.batch_size = 32\n",
    "        self.q_network = Network(self.input_size,self.action_size)\n",
    "        self.q_network_target = Network(self.input_size,self.action_size)\n",
    "        self.optimizer = optim.Adam(self.q_network.parameters(),lr=0.001)\n",
    "        \n",
    "        self.buffer_size = int(1e5)\n",
    "        \n",
    "        self.memory = deque(maxlen=self.buffer_size)\n",
    "        \n",
    "        self.time_step = 0\n",
    "        self.update_every = 4\n",
    "        \n",
    "        self.tau = 1e-3\n",
    "    def act(self,state,epsilon=None):\n",
    "        self.epsilon*=self.eps_decay\n",
    "        epsilon = self.epsilon \n",
    "        self.q_network.eval()\n",
    "        state = torch.from_numpy(state).float().view(1,*state.shape)\n",
    "        with torch.no_grad():\n",
    "            val = self.q_network(state)\n",
    "            if epsilon is not None and random.random()<epsilon:\n",
    "                return np.random.choice(np.arange(self.action_size))\n",
    "            else:\n",
    "                return np.argmax(val.data.numpy()).astype(np.int32)\n",
    "    def step(self,state,action,reward,done,next_state):\n",
    "        experience = (state,action,reward,done,next_state)\n",
    "        self.memory.append(experience)\n",
    "        \n",
    "        self.time_step = (self.time_step+1)%self.update_every\n",
    "        \n",
    "        if self.time_step == 0:\n",
    "            if len(self.memory) > self.batch_size :\n",
    "                self.train()\n",
    "    def sample(self):\n",
    "        experiences = random.sample(self.memory, k=self.batch_size)\n",
    "\n",
    "        states = torch.from_numpy(np.vstack([e[0] for e in experiences if e is not None])).float()\n",
    "        actions = torch.from_numpy(np.vstack([e[1] for e in experiences if e is not None])).long()\n",
    "        rewards = torch.from_numpy(np.vstack([e[2] for e in experiences if e is not None])).float()\n",
    "        next_states = torch.from_numpy(np.vstack([e[4] for e in experiences if e is not None])).float()\n",
    "        dones = torch.from_numpy(np.vstack([e[3] for e in experiences if e is not None]).astype(np.uint8)).float()\n",
    "  \n",
    "        return (states, actions, rewards, next_states, dones)\n",
    "    def train(self):\n",
    "        states,actions,rewards,next_states,dones = self.sample()\n",
    "        self.q_network.train()\n",
    "        \n",
    "        Q_actual = self.q_network(states).gather(1,actions)\n",
    "        q_val = self.q_network_target(next_states).detach().max(1)[0].unsqueeze(1)\n",
    "        Q_target = rewards + self.gamma*(q_val)*(1-dones)\n",
    "        \n",
    "        loss = F.mse_loss(Q_actual,Q_target)\n",
    "        self.optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        self.soft_update()\n",
    "    def soft_update(self):\n",
    "        ## θ_target = τ*θ_local + (1 - τ)*θ_target\n",
    "        for target_param, local_param in zip(self.q_network_target.parameters(), self.q_network.parameters()):\n",
    "            target_param.data.copy_(self.tau*local_param.data + (1.0-self.tau)*target_param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(state_size,action_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Watch the untrained network play \n",
    "Run the cell below to see the untrained neural network play . It would be like the agent is picking the action at random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name] # reset the environment\n",
    "state = env_info.vector_observations[0]            # get the current state\n",
    "score = 0                                          # initialize the score\n",
    "for _ in range(1000):\n",
    "    action = agent.act(state)      # select an action\n",
    "    env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "    next_state = env_info.vector_observations[0]   # get the next state\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    score += reward                                # update the score\n",
    "    state = next_state                             # roll over the state to next time step\n",
    "    if done:                                       # exit loop if episode finished\n",
    "        break\n",
    "    \n",
    "print(\"Score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Implementing the Q-Learning algorithm \n",
    "The following code cell implements the **Q-Learning** Algorithm to train the agent \n",
    "We train it from **1000** episodes . \n",
    "\n",
    "It produces an avearge score of around **14-16** after 1000 episode .To solve the enviorement we needed an average score of **13** . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 200    avg_reward = 1.015000  Avg reward of last 100 episodes : 2.04000000\n",
      "Episode 400    avg_reward = 3.630000  Avg reward of last 100 episodes : 6.120000\n",
      "Episode 600    avg_reward = 6.133333  Avg reward of last 100 episodes : 12.650000\n",
      "Episode 800    avg_reward = 8.195000  Avg reward of last 100 episodes : 14.420000\n",
      "Episode 1000    avg_reward = 9.728000  Avg reward of last 100 episodes : 16.110000\n"
     ]
    }
   ],
   "source": [
    "rewards_per_ep = []\n",
    "for i in range(1,1001):\n",
    "    env_info = env.reset(train_mode=True)[brain_name]\n",
    "    state = env_info.vector_observations[0]\n",
    "    avg_reward = 0\n",
    "    score = 0.0\n",
    "    while True:\n",
    "        action = agent.act(state)\n",
    "        env_info = env.step(action)[brain_name]\n",
    "        next_state = env_info.vector_observations[0]\n",
    "        reward = env_info.rewards[0]\n",
    "        done = env_info.local_done[0]\n",
    "        score+=reward\n",
    "        agent.step(state,action,reward,done,next_state)\n",
    "        state = next_state\n",
    "        if done:\n",
    "            break\n",
    "    rewards_per_ep.append(score)\n",
    "    avg_reward = np.mean(rewards_per_ep)\n",
    "    print(\"\\rEpisode {}    avg_reward = {:3f}  \".format(i,avg_reward),end=\"\")\n",
    "    if i > 100 :\n",
    "        reward_100 = np.mean(rewards_per_ep[-100:])\n",
    "        print(\"Avg reward of last 100 episodes : {:3f}\".format(np.mean(reward_100)),end=\"\")\n",
    "    if i % 200 == 0:\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualize the Score achieved by the Ai at each episode \n",
    "You can see the scores slowly increases as the agent optimizer its stratergy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.plot(np.arange(len(rewards_per_ep)),rewards_per_ep,label=\"Reward\",Color='b')\n",
    "plt.legend()\n",
    "plt.xlabel('Episodes')\n",
    "plt.ylabel('Scores')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the network's weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(agent.q_network.state_dict(),'checkpoint.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the saved weight's of the Q- Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.q_network.load_state_dict(torch.load('checkpoint.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Watch a Learned Agent Play \n",
    "## 8. The Fun Part\n",
    "Our agent has played the game for a quite a long time now . It's time it shows us what it learned .\n",
    "Now we will see our agent play with all the experience it has gathered . \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 19.0\n"
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name] # reset the environment\n",
    "state = env_info.vector_observations[0]            # get the current state\n",
    "score = 0                                          # initialize the score\n",
    "for _ in range(1000):\n",
    "    action = agent.act(state)      # select an action\n",
    "    env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "    next_state = env_info.vector_observations[0]   # get the next state\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    score += reward                                # update the score\n",
    "    state = next_state                             # roll over the state to next time step\n",
    "    if done:                                       # exit loop if episode finished\n",
    "        break\n",
    "    \n",
    "print(\"Score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Finally we close the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Improvement Ideas \n",
    "##### Although the AI did a good job in the game , i think it could furthur be improved by adding some improvements to the DQN algorithm like the Double DQN algorithm , Prioritized action replay etc . \n",
    "\n",
    "###### In the future I plan to furthur improve this model using the improved techniques . "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
