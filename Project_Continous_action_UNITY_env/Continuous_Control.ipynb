{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Control\n",
    "\n",
    "---\n",
    "\n",
    "You are welcome to use this coding environment to train your agent for the project.  Follow the instructions below to get started!\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "Run the next code cell to install a few packages.  This line will take a few minutes to run!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The environments corresponding to both versions of the environment are already saved in the Workspace and can be accessed at the file paths provided below.  \n",
    "\n",
    "Please select one of the two options below for loading the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "\n",
    "# select this option to load version 1 (with a single agent) of the environment\n",
    "env = UnityEnvironment(file_name='Reacher_Windows_x86_64/Reacher.exe')\n",
    "\n",
    "# select this option to load version 2 (with 20 agents) of the environment\n",
    "# env = UnityEnvironment(file_name='/data/Reacher_Linux_NoVis/Reacher.x86_64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 1\n",
      "Size of each action: 4\n",
      "There are 1 agents. Each observes a state with length: 33\n",
      "The state for the first agent looks like: [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "  1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  5.75471878e+00 -1.00000000e+00\n",
      "  5.55726671e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -1.68164849e-01]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Note that **in this coding environment, you will not be able to watch the agents while they are training**, and you should set `train_mode=True` to restart the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.05361054,  1.06940593, -0.40549144, -0.36565714]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randn(1,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score (averaged over agents) this episode: 0.0\n"
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name]      # reset the environment    \n",
    "states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)       # initialize the score (for each agent)\n",
    "for i in range(200):\n",
    "    actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "    actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "    env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "    next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "    rewards = env_info.rewards                         # get reward (for each agent)\n",
    "    dones = env_info.local_done                        # see if episode finished\n",
    "    scores += env_info.rewards                         # update the score (for each agent)\n",
    "    states = next_states                               # roll over states to next time step\n",
    "    if np.any(dones):                                  # exit loop if episode finished\n",
    "        break\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  A few **important notes**:\n",
    "- When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```\n",
    "- To structure your work, you're welcome to work directly in this Jupyter notebook, or you might like to start over with a new file!  You can see the list of files in the workspace by clicking on **_Jupyter_** in the top left corner of the notebook.\n",
    "- In this coding environment, you will not be able to watch the agents while they are training.  However, **_after training the agents_**, you can download the saved model weights to watch the agents on your own machine! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np \n",
    "from torch.distributions import Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self,input_size,output_size,std=0.00001):\n",
    "        super().__init__()\n",
    "        self.critic_1 = nn.Linear(input_size,32)\n",
    "        self.critic_2 = nn.Linear(32,1)\n",
    "        \n",
    "        self.mean_1 = nn.Linear(input_size,256)\n",
    "        self.mean_2 = nn.Linear(256,64)\n",
    "        self.mean_3 = nn.Linear(64,output_size)\n",
    "        \n",
    "        self.log_std = nn.Parameter(torch.ones(1, output_size) * std)\n",
    "        \n",
    "    def forward(self,state):\n",
    "        state = torch.from_numpy(state).float()\n",
    "        \n",
    "        mean = F.relu(self.mean_1(state))\n",
    "        mean = F.relu(self.mean_2(mean))\n",
    "        mean = F.tanh(self.mean_3(mean))\n",
    "\n",
    "        std = self.log_std.exp().expand_as(mean)\n",
    "        dist = torch.distributions.Normal(mean,std)\n",
    "        \n",
    "        critic = F.relu(self.critic_1(state))\n",
    "        critic = self.critic_2(critic)\n",
    "        \n",
    "        return dist,critic\n",
    "    def critic(self,state):\n",
    "        \n",
    "        state = torch.from_numpy(state).float()\n",
    "        critic = F.relu(self.critic_1(state))\n",
    "        critic = self.critic_2(critic)\n",
    "        return critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Network(state_size,action_size)\n",
    "optimizer = optim.Adam(model.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma=0.99\n",
    "n_episodes = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pratik Agarwal\\miniconda3\\envs\\drlnd\\lib\\site-packages\\torch\\nn\\functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 192 , Avg reward : 0.184896 , Score : 0.000000 "
     ]
    }
   ],
   "source": [
    "reward_per_ep=[]\n",
    "for i in range(n_episodes):\n",
    "    env_info = env.reset(train_mode=True)[brain_name]\n",
    "    state = env_info.vector_observations\n",
    "    rewards = 0\n",
    "    for j in range(1000):\n",
    "        dist,critic = model(state)\n",
    "        action = dist.sample()\n",
    "        action = action.squeeze(0)\n",
    "        env_info = env.step(action.numpy())[brain_name]\n",
    "        next_state = env_info.vector_observations\n",
    "        reward = env_info.rewards\n",
    "        rewards += reward[0]\n",
    "        done = env_info.local_done\n",
    "        v_next = model.critic(next_state)\n",
    "        critic = critic.squeeze(0)\n",
    "        \n",
    "        advantage = (torch.tensor(reward)+gamma*v_next-critic)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        #td.backward()\n",
    "        \n",
    "        critic_error = (advantage.pow(2)*0.5).mean()\n",
    "        actor_error = -(dist.log_prob(action) * advantage).mean()\n",
    "        entropy = dist.entropy()\n",
    "        \n",
    "        loss = critic_error + actor_error - 0.0001 * entropy\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        state = next_state\n",
    "        if done[0] or j==999:\n",
    "            reward_per_ep.append(rewards)\n",
    "            print(\"\\rEpisode {} , Avg reward : {:3f} , Score : {:3f} \".format(i+1,np.mean(reward_per_ep),rewards),end=\"\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(np.arange(len(reward_per_ep)),reward_per_ep)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using PPO \n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self,input_size,output_size,std=0.0):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.actor = nn.Sequential(nn.Linear(input_size,32),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Linear(32,16) ,\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Linear(16,output_size),\n",
    "                                  nn.Tanh())\n",
    "        self.critic = nn.Sequential(nn.Linear(input_size,32),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(32,16),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(16,1))\n",
    "        self.log_std = nn.Parameter(torch.ones(1,output_size)*std)\n",
    "    def forward(self,state):\n",
    "        value = self.critic(state)\n",
    "        mu = self.actor(state)\n",
    "        std = self.log_std.exp()\n",
    "        dist = Normal(mu,std)\n",
    "        return dist,value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_env = 8 \n",
    "gamma = 0.99\n",
    "lr = 1e-6\n",
    "gae_lambda = 0.95\n",
    "epsilon = 0.2\n",
    "entropy_beta = 0.001\n",
    "critic_discount = 0.5\n",
    "PPO_STEPS = 200\n",
    "mini_batch = 32\n",
    "ppo_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gae(next_value,rewards,masks,values,gamma=gamma,lam=gae_lambda):\n",
    "    values = values+[next_value]\n",
    "    gae = 0 \n",
    "    returns = []\n",
    "    for step in reversed(range(len(rewards))):\n",
    "        delta = rewards[step] + gamma*values[step+1]*masks[step] - values[step]\n",
    "        gae = delta + gamma * lam * masks[step] *gae\n",
    "        returns.insert(0,gae + values[step])\n",
    "    return returns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + 1e-8)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_env(train_mode=False):\n",
    "    env_info = env.reset(train_mode)[brain_name]     # reset the environment    \n",
    "    states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "    scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "    \n",
    "    while True:\n",
    "        actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "        actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "        env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "        next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "        rewards = env_info.rewards                         # get reward (for each agent)\n",
    "        dones = env_info.local_done                        # see if episode finished\n",
    "        scores += env_info.rewards                         # update the score (for each agent)\n",
    "        states = next_states                               # roll over states to next time step\n",
    "        if np.any(dones):                                  # exit loop if episode finished\n",
    "            break\n",
    "    print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppo_iter(states, actions, log_probs, returns, advantage):\n",
    "    batch_size = states.size(0)\n",
    "    # generates random mini-batches until we have covered the full batch\n",
    "    for _ in range(batch_size // mini_batch):\n",
    "        rand_ids = np.random.randint(0, batch_size, mini_batch)\n",
    "        yield states[rand_ids, :], actions[rand_ids, :], log_probs[rand_ids, :], returns[rand_ids, :], advantage[rand_ids, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppo_update(states,actions,log_probs,returns,advantages,clip=epsilon):\n",
    "    for ep in range(ppo_epochs):\n",
    "        for state,action,old_log_prob,return_,advantage in ppo_iter(states,actions,log_probs,returns,advantages):\n",
    "            dist,value = model(state)\n",
    "            entropy = dist.entropy().mean()\n",
    "            new_log_prob = dist.log_prob(action)\n",
    "            \n",
    "            ratio = (new_log_prob-old_log_prob).exp()\n",
    "        \n",
    "            surr1 = ratio*advantage\n",
    "            surr2 = torch.clamp(ratio,1.0-clip,1.0+clip)*advantage\n",
    "            \n",
    "            actor_loss = -torch.min(surr1,surr2).mean()\n",
    "            critic_loss = (return_-value).pow(2).mean()\n",
    "            \n",
    "            loss = 0.5*critic_loss + actor_loss - entropy_beta*entropy\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(),5)\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ActorCritic(state_size,action_size)\n",
    "optimizer = optim.Adam(model.parameters(),lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "state = env_info.vector_observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist,value = model(torch.FloatTensor(state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.11983119, -0.8575052 , -0.87771356, -0.52017045]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.clip(dist.sample().numpy(),-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 10 , Score : 0.000000"
     ]
    }
   ],
   "source": [
    "n_episodes = 10\n",
    "best = 5\n",
    "for ep in range(n_episodes):\n",
    "    env_info = env.reset(train_mode=True)[brain_name]\n",
    "    state = env_info.vector_observations\n",
    "    log_probs = []\n",
    "    values = []\n",
    "    states = []\n",
    "    actions = []\n",
    "    rewards = []\n",
    "    masks = []\n",
    "    score = 0\n",
    "    c=0\n",
    "    for _ in range(PPO_STEPS):\n",
    "        state = torch.FloatTensor(state)\n",
    "        dist,value = model(state)\n",
    "        action = dist.sample()\n",
    "        env_info = env.step(np.clip(action.numpy(),-1,1))[brain_name]\n",
    "        next_state = env_info.vector_observations\n",
    "        reward = env_info.rewards\n",
    "        done = env_info.local_done[0]\n",
    "        log_prob = dist.log_prob(action)\n",
    "        \n",
    "        log_probs.append(log_prob)\n",
    "        values.append(value)\n",
    "        rewards.append(torch.FloatTensor(reward).unsqueeze(1))\n",
    "        masks.append(torch.FloatTensor(1-done).unsqueeze(1))\n",
    "        states.append(state)  \n",
    "        actions.append(action)\n",
    "        \n",
    "        state = next_state\n",
    "        score += reward[0]\n",
    "    \n",
    "    next_state = torch.FloatTensor(next_state)\n",
    "    _,next_value = model(next_state)\n",
    "    returns = compute_gae(next_value,rewards,masks,values)\n",
    "    returns   = torch.cat(returns).detach()\n",
    "    log_probs = torch.cat(log_probs).detach()\n",
    "    values    = torch.cat(values).detach()\n",
    "    states    = torch.cat(states)\n",
    "    actions   = torch.cat(actions)\n",
    "    \n",
    "    advantage = returns - values\n",
    "    #advantage = normalize(advantage)\n",
    "    ppo_update(states,actions,log_probs,returns,advantage)\n",
    "    \n",
    "    \n",
    "    print(\"\\rEpisode {} , Score : {:3f}\".format(ep+1,score),end=\"\")\n",
    "    if ep > 100 :\n",
    "        print(\" Avg of last 100 : {:2f} \".format(np.mean(reward_per_ep[-100:])),end=\"\")\n",
    "    if score> best:\n",
    "        print(\"Best Reward updated \",best,\" =====> \",test_reward)\n",
    "        best = score\n",
    "        name = 'checkpoint_{}.pt'.format(best)\n",
    "        torch.save(model.state_dict(),name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[nan, nan, nan, nan]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([nan, nan, nan, nan], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([nan], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
